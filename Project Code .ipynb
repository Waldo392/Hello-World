{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import scipy.special\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network:\n",
    "    \n",
    "    def __init__(self,inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5),(self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5),(self.onodes,self.hnodes))\n",
    "        \n",
    "        self.lr = learningrate\n",
    "        \n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "      # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "    # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "    # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "    # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "    # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "    # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "    # output layer error is the (target actual)\n",
    "        output_errors = targets-final_outputs\n",
    "    # hidden layer error is the output_errors, split by weights,recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "    # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0-final_outputs)),numpy.transpose(hidden_outputs))\n",
    "    # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors *hidden_outputs * (1.0-hidden_outputs)), numpy.transpose(inputs))\n",
    "    pass\n",
    "    \n",
    "    def query(self, inputs_list):\n",
    "    # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes=784\n",
    "hidden_nodes= 100\n",
    "output_nodes = 10\n",
    "learning_rate = 0.2\n",
    "\n",
    "n= neural_network(input_nodes,hidden_nodes,output_nodes,learning_rate)\n",
    "\n",
    "#MNIST dataset \n",
    "train_data_file = open(\"mnist_train.csv\", 'r')\n",
    "train_data_list = train_data_file.readlines()\n",
    "train_data_file.close()\n",
    "\n",
    "#adding epochs\n",
    "epoch=5 \n",
    "#Training the Neural network \n",
    "for e in range(epoch):\n",
    "    for record in train_data_list:\n",
    "        all_values = record.split(',')\n",
    "\n",
    "        #Scaling and shifting of the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:])/255.0 * 0.99) + 0.01\n",
    "\n",
    "        #0-9 setting the target valuse of the node, from MNIST dataset chosing the first cell and setting that number to have prob 0.99\n",
    "        targets = numpy.zeros(output_nodes)+0.01\n",
    "        targets[int(all_values[0])]=0.99\n",
    "\n",
    "\n",
    "        n.train(inputs,targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00790319],\n",
       "       [0.02096725],\n",
       "       [0.00821454],\n",
       "       [0.05677263],\n",
       "       [0.02779267],\n",
       "       [0.00786807],\n",
       "       [0.0288586 ],\n",
       "       [0.98350549],\n",
       "       [0.00586498],\n",
       "       [0.03841602]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the neural network\n",
    "test_data_file= open(\"mnist_test.csv\",'r')\n",
    "test_data_list= test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "#Scorecard\n",
    "scorecard=[]\n",
    "sum=0\n",
    "all_values=test_data_list[0].split(',')\n",
    "n.query((numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9601\n"
     ]
    }
   ],
   "source": [
    "for record in test_data_list:\n",
    "    #splitting the comma seperated values\n",
    "    all_values = record.split(',')\n",
    "    #Correct answer is the 0th order valuw of the data set\n",
    "    correct_label=int(all_values[0])\n",
    "    #print(\"Correct answer=\",correct_label)\n",
    "    \n",
    "    inputs = (numpy.asfarray(all_values[1:])/255.0 * 0.99)+0.01\n",
    "\n",
    "    #query the network\n",
    "    outputs= n.query(inputs)\n",
    "  \n",
    "    #highest value is the label predicted by network\n",
    "    label=numpy.argmax(outputs)\n",
    "    #print('network answer=',label)\n",
    "    #appending correct or incorrect to the scorecard \n",
    "    if(label==correct_label):\n",
    "        scorecard.append(1)\n",
    "        sum=sum+1\n",
    "    else:\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "img_array = imageio.imread ( \"1bpng.png\", as_gray = True )\n",
    "img_data = 255.0 - img_array.reshape(784)\n",
    "img_data = (img_data / 255.0 * 0.99 ) + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(numpy.argmax(n.query(img_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
